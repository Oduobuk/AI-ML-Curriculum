# Week 2: Dimensionality Reduction & Feature Engineering

## ğŸ“š Learning Objectives
By the end of this week, you should be able to:
- Understand the curse of dimensionality and when to apply dimensionality reduction
- Implement and apply PCA for feature extraction and visualization
- Use t-SNE and UMAP for non-linear dimensionality reduction
- Apply feature selection techniques to improve model performance
- Build pipelines that incorporate dimensionality reduction

## ğŸ—“ Weekly Schedule

### Day 1: Introduction to Dimensionality Reduction
- Morning: Curse of Dimensionality & PCA Theory
- Afternoon: Implementing PCA from scratch
- Exercise: Apply PCA to a high-dimensional dataset

### Day 2: Advanced Dimensionality Reduction
- Morning: t-SNE and UMAP algorithms
- Afternoon: Visualizing high-dimensional data
- Exercise: Compare PCA, t-SNE, and UMAP on different datasets

### Day 3: Feature Selection
- Morning: Filter, Wrapper, and Embedded methods
- Afternoon: Feature importance and selection techniques
- Exercise: Implement feature selection on a real-world dataset

### Day 4: Building ML Pipelines
- Morning: Scikit-learn pipelines
- Afternoon: Combining preprocessing, feature selection, and models
- Exercise: Build an end-to-end ML pipeline

### Day 5: Project Work & Review
- Morning: Work on weekly project
- Afternoon: Code reviews and knowledge sharing
- Project Submission

## ğŸ‹ï¸ Exercises
1. **PCA Implementation**: Implement PCA from scratch and compare with scikit-learn
2. **t-SNE vs UMAP**: Compare the performance and visualization quality of t-SNE and UMAP
3. **Feature Selection**: Apply different feature selection techniques to a dataset
4. **ML Pipeline**: Build a complete ML pipeline with dimensionality reduction

## ğŸ— Project: Dimensionality Reduction for Image Data
Apply different dimensionality reduction techniques to an image dataset and analyze:
- How much can we reduce dimensions while maintaining good classification performance?
- Which technique works best for visualization?
- How do different techniques affect model training time and performance?

## ğŸ“– Resources
### Required Reading
- [PCA Tutorial by Sebastian Raschka](https://sebastianraschka.com/Articles/2014_pca_step_by_step.html)
- [How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)
- [UMAP Documentation](https://umap-learn.readthedocs.io/en/latest/)

### Additional Resources
- [Dimensionality Reduction - Towards Data Science](https://towardsdatascience.com/dimensionality-reduction-does-more-than-to-reduce-the-number-of-features-479fb4f5e9b9)
- [Interactive t-SNE Demo](https://observablehq.com/@nstrayer/dimensionality-reduction)
- [Feature Selection in Python](https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/)

## ğŸ¯ Prerequisites
- Python 3.7+
- NumPy
- Pandas
- Matplotlib/Seaborn
- scikit-learn
- umap-learn
- plotly (for interactive visualizations)

## ğŸ“Š Assessment
- Weekly Quiz (20%)
- Exercise Submissions (40%)
- End-of-Week Project (40%)

## ğŸš€ Getting Started
1. Clone the repository
2. Create a new branch: `git checkout -b week2-submission`
3. Work through the exercises in the `exercises/` directory
4. Complete the weekly project
5. Submit a pull request with your solutions

Happy Learning! ğŸ‰
