 Month 3, Week 4: Reading Materials & Resources

This week is about building a foundational understanding of neural networks. The following resources will help you dive deeper into the concepts introduced in the lecture.



 1. Core Concepts (Highly Recommended)

These resources provide the conceptual and mathematical backbone for this week's topic.

- 3Blue1Brown - Neural Networks Series
  - The lecture notes were heavily inspired by this series. Grant Sanderson provides some of the best visual intuitions for what neural networks are, how they work, and why backpropagation is what it is.
  - Video 1: [What is a neural network?](https://www.youtube.com/watch?v=aircAruvnKk)
  - Video 2: [Gradient descent, how neural networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w)
  - Video 3: [What is backpropagation, really?](https://www.youtube.com/watch?v=Ilg3gGewQ5U)

- "Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville
  - This is often considered the foundational textbook for deep learning. It is comprehensive and mathematically rigorous.
  - Chapter 6: [Deep Feedforward Networks](https://www.deeplearningbook.org/contents/mlp.html): This chapter covers everything from the basic structure of a neural network to activation functions, cost functions, and the backpropagation algorithm in great detail.



 2. Practical Implementation & Further Reading

These resources provide more context on practical implementation and common practices.

- Michael Nielsen - "Neural Networks and Deep Learning"
  - A free online book that provides a wonderfully clear, step-by-step guide to building a neural network from scratch to classify MNIST digits. The code examples are in Python 2 but are easily adaptable.
  - Chapter 1: [Using neural nets to recognize handwritten digits](http.://neuralnetworksanddeeplearning.com/chap1.html)
  - Chapter 2: [How the backpropagation algorithm works](http.://neuralnetworksanddeeplearning.com/chap2.html)

- Stanford's CS231n Course Notes
  - While focused on Convolutional Neural Networks for vision, the early notes provide an excellent and concise overview of the core components.
  - [Module 1: Neural Networks Part 1-3](https://cs231n.github.io/neural-networks-1/): Covers activation functions, data preprocessing, and weight initialization.
  - [Module 1: Neural Networks Part 4](https://cs231n.github.io/neural-networks-2/): A deeper dive into backpropagation.

- Chris Olah's Blog
  - Known for beautiful and intuitive explanations of complex deep learning topics.
  - [Calculus on Computational Graphs: Backpropagation](https://colah.github.io/posts/2015-08-Backprop/): A fantastic visual explanation of backpropagation as a process of flowing gradients through a computational graph.



 3. Datasets

- The MNIST Database of Handwritten Digits
  - The classic "hello world" dataset for deep learning. You can read about its structure and download it directly from Yann LeCun's website.
  - [Official Website](http.://yann.lecun.com/exdb/mnist/)
  - [Download Link for the `pkl.gz` version](http.://deeplearning.net/data/mnist/mnist.pkl.gz) (as used in the code example).

Happy learning!
