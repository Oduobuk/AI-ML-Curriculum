# Month 5, Week 3: Explainable & Responsible AI Conceptual Exercises

## Instructions
These exercises are designed to make you think critically about the ethical and practical challenges of building and deploying AI systems. Write down your answers and be prepared to discuss them.

## Exercises

1.  **Interpretability vs. Performance:**
    *   There is often a trade-off between a model's performance (e.g., accuracy) and its interpretability. For example, a simple linear model is highly interpretable but may not be as accurate as a complex deep neural network.
    *   Describe a real-world scenario where you would prioritize **interpretability over performance**. Justify your choice.
    *   Describe a real-world scenario where you would prioritize **performance over interpretability**. Justify your choice.

2.  **The "Right to Explanation":**
    *   Some regulations, like the GDPR, suggest that individuals have a "right to explanation" for decisions made by automated systems.
    *   What are the challenges in providing a meaningful explanation to a non-technical person for a decision made by a complex model like a neural network?
    *   Do you think a LIME or SHAP explanation would be sufficient to satisfy this "right to explanation"? Why or why not?

3.  **Bias in, Bias out:**
    *   The phrase "garbage in, garbage out" is often used in programming. In machine learning, it can be adapted to "bias in, bias out."
    *   Explain what this means. How can historical biases present in data lead to unfair or discriminatory AI models?
    *   Imagine you are building a model to predict who is likely to be a successful job applicant. What are some potential sources of bias in the data you might use? How could this lead to an unfair hiring model?

4.  **Fairness Metrics:**
    *   There are many different mathematical definitions of fairness (e.g., demographic parity, equalized odds, equal opportunity).
    *   Why is there no single, universally accepted definition of fairness?
    *   Choose two fairness metrics and explain what they measure. Can a model satisfy both of them simultaneously? (Hint: Look up the "impossibility theorem of fairness.")

5.  **Accountability and Responsibility:**
    *   An autonomous vehicle with an AI-powered navigation system is involved in an accident. Who is accountable?
    *   Consider the different parties involved: the owner of the car, the manufacturer of the car, the company that developed the AI software, the engineer who wrote the code, the person who collected the training data, etc.
    *   Discuss the challenges in assigning responsibility in complex AI systems. What kind of framework or regulations would be needed to address this?

6.  **The Role of Transparency:**
    *   Some companies are hesitant to be fully transparent about their AI models, citing concerns about intellectual property or the risk of adversarial attacks.
    *   What are the arguments for and against full transparency in AI?
    *   How can we balance the need for transparency with legitimate business and security concerns?
